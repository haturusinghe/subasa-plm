{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Subasa: For Testing Final Model",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": [
                "--pretrained_model", "xlm-roberta-base",
                "--val_int", "600",
                "--patience", "3",
                "--batch_size", "1",
                "--seed", "42",
                "--wandb_project", "subasa-xlmr-base-session1",
                "--finetuning_stage", "final",
                "--num_labels", "2",
                "--dataset", "sold",
                "--test", "True",
                "--model_path", "final_finetune/08012025-1353_LK_xlm-roberta-base_mrp_2e-05_16_600_seed42_ncls2_final/08012025-1353_LK_xlm-roberta-base_mrp_2e-05_16_600_seed42_ncls2_final.ckpt"
            ]
        },
        {
            "name": "Subasa: For Training MRP Model",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": [
                "--pretrained_model", "xlm-roberta-base",
                "--intermediate", "mrp",
                "--val_int", "3700",
                "--patience", "3",
                "--mask_ratio", "0.5",
                "--n_tk_label", "2",
                "--epochs", "5",
                "--batch_size", "1",
                "--lr", "0.00002",
                "--seed", "42",
                "--wandb_project", "subasa-xlmr-base-session1",
                "--finetuning_stage", "pre",
                "--dataset", "sold",
                "--skip_empty_rat", "True",
                // "--test", "False",
                // "--check_errors", "False",
            ]
        },
        {
            "name": "Subasa: Train for OffensiveDetection (Final)",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": [
                "--pretrained_model", "xlm-roberta-base",
                "--val_int", "250",
                "--patience", "3",
                "--epochs", "5",
                "--batch_size", "16",
                "--lr", "0.00002",
                "--seed", "42",
                "--wandb_project", "subasa-xlmr-base-session1",
                "--finetuning_stage", "final",
                "--dataset", "sold",
                "--num_labels", "2",
                "--pre_finetuned_model", "pre_finetune/09012025-1343_LK_2e-05_16_250_seed42_xlm-roberta-base_mrp_pre/xlm-roberta-base_mrp_val_loss_0.115060_ep4_stp249_f1_0.625580.ckpt"
            ]
        },
        {
            "name": "Subasa: Testing Final Model After Finetuneing for OffensiveDetection (Final)",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": [
                "--pretrained_model", "xlm-roberta-base",
                "--val_int", "2500",
                "--patience", "3",
                "--epochs", "1",
                "--batch_size", "1",
                "--seed", "42",
                "--wandb_project", "subasa-xlmr-base-session1",
                "--finetuning_stage", "final",
                "--dataset", "sold",
                "--num_labels", "2",
                "--test", "True",
                "--test_model_path", "final_finetune/09012025-1650_LK_2e-05_16_250_seed42_final/xlm-roberta-base_final__val_loss_0.438462_ep4_stp249_f1_0.841653.ckpt"
            ]
        },

        {
            "name": "Subasa: Testing MRP Model after Pre-Finetuning Phase",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": [
                "--pretrained_model", "xlm-roberta-base",
                "--val_int", "2500",
                "--patience", "3",
                "--epochs", "1",
                "--batch_size", "1",
                "--seed", "42",
                "--wandb_project", "subasa-xlmr-base-session1",
                "--finetuning_stage", "pre",
                "--dataset", "sold",
                "--num_labels", "2",
                "--skip_empty_rat", "True",
                "--test", "True",
                "--intermediate", "mrp",
                "--test_model_path", "pre_finetune/09012025-1343_LK_2e-05_16_250_seed42_xlm-roberta-base_mrp_pre/xlm-roberta-base_mrp_val_loss_0.115060_ep4_stp249_f1_0.625580.ckpt"
            ]
        }
        
    ]
}
